{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XElFSD-OZVa0"
   },
   "source": [
    "# Prediction Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJB6am0yS6G-"
   },
   "source": [
    "## Load Modules, Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "id": "x3f2R0lbZTx9",
    "outputId": "c1ee3000-0f7c-4da4-fbad-b1f6180dfa5b"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV, RandomizedSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, make_scorer, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, FunctionTransformer, RobustScaler, KBinsDiscretizer, StandardScaler\n",
    "from sklearn.base import clone\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/dataset.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCXSyMmfSuru"
   },
   "source": [
    "### Make additional categorical feature out of days_since_last_contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IrMlKjGUAuTS"
   },
   "outputs": [],
   "source": [
    "df['days_since_last_contact'] = np.where(df['days_since_last_contact'].between(1,5), 1, df['days_since_last_contact'])\n",
    "df['days_since_last_contact'] = df['days_since_last_contact'].mask(df['days_since_last_contact'] >= 6, 2)\n",
    "df['days_since_last_contact'] = df['days_since_last_contact'].mask(df['days_since_last_contact'] == -1, 999)\n",
    "\n",
    "df['days_since_last_contact_cat'] = np.where(df['days_since_last_contact'].between(1,5), 1, df['days_since_last_contact'])\n",
    "df['days_since_last_contact_cat'] = df['days_since_last_contact'].mask(df['days_since_last_contact'] >= 6, 2)\n",
    "df['days_since_last_contact_cat'] = df['days_since_last_contact'].mask(df['days_since_last_contact'] == -1, 999)\n",
    "df['days_since_last_contact_cat'] = np.where(df['days_since_last_contact_cat'].between(1,5), 1, df['days_since_last_contact'])\n",
    "df['days_since_last_contact_cat'] = df['days_since_last_contact_cat'].mask(df['days_since_last_contact'] >= 6, 2)\n",
    "df['days_since_last_contact_cat'] = df['days_since_last_contact_cat'].mask(df['days_since_last_contact'] == -1, 999)\n",
    "\n",
    "df['n_contacts_before'] = np.where(df['n_contacts_before'].between(2,4), 1, df['n_contacts_before'])\n",
    "df['n_contacts_before'] = df['n_contacts_before'].mask(df['n_contacts_before'] == 0, 0)\n",
    "df['n_contacts_before'] = np.where(df['n_contacts_before'].between(5,6), 2, df['n_contacts_before'])\n",
    "df['n_contacts_before'] = df['n_contacts_before'].mask(df['n_contacts_before'] == 7, 3)\n",
    "\n",
    "df['previous_conversion_bin'] = df['previous_conversion'].mask(df['previous_conversion'] == \"Inexistent\", 0)\n",
    "df['previous_conversion_bin'] = df['previous_conversion'].mask(df['previous_conversion'] == \"Failed\", 2)\n",
    "df['previous_conversion_bin'] = df['previous_conversion'].mask(df['previous_conversion'] == \"Successful\", 1)\n",
    "df['previous_conversion_bin'] = df['previous_conversion_bin'].mask(df['previous_conversion'] == \"Inexistent\", 0)\n",
    "df['previous_conversion_bin'] = df['previous_conversion_bin'].mask(df['previous_conversion'] == \"Failed\", 2)\n",
    "df['previous_conversion_bin'] = df['previous_conversion_bin'].mask(df['previous_conversion'] == \"Successful\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dpq7o4ovTYIa"
   },
   "outputs": [],
   "source": [
    "df[\"days_since_last_contact_cat\"] = df[\"days_since_last_contact_cat\"].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07a92S9cTYZl"
   },
   "outputs": [],
   "source": [
    "df[\"n_contacts_before\"] = df[\"n_contacts_before\"].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDNuQt4X2NRR"
   },
   "source": [
    "## Featuretool for finding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L_DmyTk7UtaZ"
   },
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "import featuretools.variable_types as vtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pd.set_option('display.max_columns', None)\\npd.set_option('display.max_rows', None)\\nft.primitives.list_primitives()\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "ft.primitives.list_primitives()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LvrF2vUzVNI3",
    "outputId": "0bb5c5cb-5161-4e39-84e9-54a1e5e513eb"
   },
   "outputs": [],
   "source": [
    "es = ft.EntitySet(id = 'dataset')\n",
    "\n",
    "variable_types = {\"identifier\": vtypes.Index, \"age\":vtypes.Ordinal ,\"marital_status\": vtypes.Categorical, \n",
    "                                                \"education\": vtypes.Categorical, \"job\": vtypes.Categorical, \"credit_default\": vtypes.Boolean, \n",
    "                                                \"housing_loan\": vtypes.Boolean, \"personal_loan\": vtypes.Boolean, \"communication_type\": vtypes.Categorical,\n",
    "                                                \"n_contacts_before\": vtypes.variable.Ordinal, \"previous_conversion\": vtypes.Categorical, \n",
    "                                                \"duration\": vtypes.Datetime, \"success\": vtypes.Boolean, \"previous_conversion_bin\": vtypes.Categorical,\n",
    "                                                \"days_since_last_contact_cat\": vtypes.Categorical}\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id='dataset', \n",
    "                              dataframe = df, \n",
    "                              index = 'identifier', \n",
    "                              time_index = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.normalize_entity(base_entity_id='dataset', new_entity_id='days_since_last_contact', index='days_since_last_contact')\n",
    "es = es.normalize_entity(base_entity_id='dataset', new_entity_id='previous_conversion', index='previous_conversion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 114 features\n",
      "Elapsed: 00:01 | Progress: 100%|██████████\n"
     ]
    }
   ],
   "source": [
    "df, df_names = ft.dfs(entityset=es, \n",
    "    target_entity = 'dataset', \n",
    "    max_depth = 2, \n",
    "    verbose = 3, \n",
    "    n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for removing correlated variables \n",
    "threshold = 0.7  # Absolute value correlation matrix \n",
    "\n",
    "corr_matrix = df.corr().abs() \n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Select columns with correlations above threshold \n",
    "collinear_features = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "df = df.drop(columns = collinear_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9m8yvsGiC0W"
   },
   "outputs": [],
   "source": [
    "df = df.loc[:,df.apply(pd.Series.nunique) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37069, 26)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oIo4s_-CyW46"
   },
   "source": [
    "## Regular Oversampling of minority class\n",
    "Here the code samples our miniority class of \"Yes\" cases up three times to even out some of the unbalanced dataset to reduce the overall failure-proof quality of the learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     32893\n",
       "Yes     4176\n",
       "Name: success, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['success'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "k6FWqOZeySHX",
    "outputId": "60933976-b13e-4ffc-b461-0b5fb3e5673e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     32893\n",
       "Yes    15000\n",
       "Name: success, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.success=='No']\n",
    "df_minority = df[df.success=='Yes']\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=15000,   \n",
    "                                 random_state=1909) \n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df.success.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oIZqlvxj0v0Z"
   },
   "source": [
    "## X,y definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XlUHa_KjjhNP"
   },
   "outputs": [],
   "source": [
    "df.drop('duration', axis=1)\n",
    "X, y = df.drop('success', axis=1), df.success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VSdcTni7bT3h"
   },
   "source": [
    "## Splitting into Train and Test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zknZXlFCaBdy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=1909)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1909, stratify=y, shuffle=True, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [27010 25435 37847 ... 23406 32851 45873] TEST: [23991 32607 32400 ...   465 24879 25828]\n",
      "TRAIN: [31298  7534  7322 ... 10454 39772 46240] TEST: [11833 21328 16549 ... 18170 43726  8489]\n",
      "TRAIN: [40557  3719  7896 ... 29712 14488 39656] TEST: [ 6770 15107 26796 ... 14578  1051 24131]\n",
      "TRAIN: [ 3298 17413  5743 ... 45201  5288 17684] TEST: [34871 15574 13776 ... 22869  3089 35656]\n",
      "TRAIN: [ 7547 39047  6518 ... 21288  4192  9584] TEST: [26373  5786  9308 ... 36066 27950 23459]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "nqLqBpVLZxLI",
    "outputId": "e212200c-8045-49e1-f058-8cdd4a47d544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47893, 25)\n",
      "(47893,)\n",
      "(14368, 25)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "5zWaP-A9ON66",
    "outputId": "c9a62fa7-5fe6-4ab1-bb16-155d3aae0192"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64       9\n",
       "float64     2\n",
       "object     14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes.groupby(X.dtypes).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cat_ct',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('ft_pcontacted_last_campaign',\n",
       "                                                  FunctionTransformer(accept_sparse=False,\n",
       "                                                                      check_inverse=True,\n",
       "                                                                      func=<function ft_pcontacted_last_campaign at 0x7f3183262e50>,\n",
       "                                                                      inv_kw_args=None,\n",
       "                                                                      inverse_func=None,\n",
       "                                                                      kw_args=None,\n",
       "                                                                      validate...\n",
       "                                                 ('ft_campaign_gte10',\n",
       "                                                  FunctionTransformer(accept_sparse=False,\n",
       "                                                                      check_inverse=True,\n",
       "                                                                      func=<function ft_campaign_gte10 at 0x7f317e607160>,\n",
       "                                                                      inv_kw_args=None,\n",
       "                                                                      inverse_func=None,\n",
       "                                                                      kw_args=None,\n",
       "                                                                      validate=False),\n",
       "                                                  'n_contacts_campaign')],\n",
       "                                   verbose=False)),\n",
       "                ('ohe',\n",
       "                 OneHotEncoder(categories='auto', drop=None,\n",
       "                               dtype=<class 'numpy.float64'>,\n",
       "                               handle_unknown='ignore', sparse=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ft_pcontacted_last_campaign(X):\n",
    "    pcontacted = ~(X == 999) & (X == -1)\n",
    "    return pcontacted.values.reshape(-1,1)\n",
    "\n",
    "def ft_pcampaign(X):\n",
    "    pcampaign = ~(X == 'Inexistent')\n",
    "    return pcampaign.values.reshape(-1,1)\n",
    "\n",
    "def ft_previous(X):\n",
    "    previous = X.astype(str)\n",
    "    return previous.values.reshape(-1,1)\n",
    "\n",
    "def ft_campaign_gte10(X):\n",
    "    campaign_gte10 = X >= 10\n",
    "    return campaign_gte10.values.reshape(-1,1)\n",
    "\n",
    "def ft_campaign_to_previous(X):\n",
    "    ratio = lambda x: 0 if (X.n_contacts_before).all() == 0 else (X.n_contacts_campaign).all() / (X.n_contacts_before).all()\n",
    "    campaign_to_previous = X[['n_contacts_campaign', 'n_contacts_before']].apply(ratio, axis=1)\n",
    "    return campaign_to_previous.values.reshape(-1,1)\n",
    "\n",
    "add_pcontacted_last_campaign = FunctionTransformer(ft_pcontacted_last_campaign, validate=False)\n",
    "add_pcampaign = FunctionTransformer(ft_pcampaign, validate=False)\n",
    "add_previous = FunctionTransformer(ft_previous, validate=False)\n",
    "add_campaign_gte10 = FunctionTransformer(ft_campaign_gte10, validate=False)\n",
    "add_campaign_to_previous = FunctionTransformer(ft_campaign_to_previous, validate=False)\n",
    "\n",
    "cat_features = [\n",
    "        ('ft_pcontacted_last_campaign', add_pcontacted_last_campaign, 'days_since_last_contact'),\n",
    "        ('ft_pcampaign', add_pcampaign, 'previous_conversion'),\n",
    "        ('ft_previous', add_previous, 'n_contacts_before'),\n",
    "        ('ft_campaign_gte10', add_campaign_gte10, 'n_contacts_campaign')]\n",
    "\n",
    "cat_ct = ColumnTransformer(cat_features)\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "  ('cat_ct', cat_ct),\n",
    "  ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "cat_pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_pipeline = Pipeline([\n",
    "  ('log', FunctionTransformer(np.log, validate=True)),\n",
    "  ('kbins', KBinsDiscretizer())\n",
    "])\n",
    "\n",
    "new_num_features = [\n",
    "    ('ft_campaign_to_previous', FunctionTransformer(ft_campaign_to_previous, validate=False))\n",
    "]\n",
    "\n",
    "num_union = FeatureUnion(new_num_features)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('num_union', num_union),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "age_campaign_ct = ColumnTransformer([\n",
    "  ('age_pipeline', clone(binning_pipeline), ['age']),\n",
    "  ('campaign_pipeline', clone(binning_pipeline), ['n_contacts_campaign'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33525, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.fit(X_train)\n",
    "cat_ct.fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ft_pcampaign_False',\n",
       " 'ft_previous_False',\n",
       " 'ft_previous_True',\n",
       " 'ft_campaign_gte10_0',\n",
       " 'ft_campaign_gte10_1',\n",
       " 'ft_campaign_gte10_2',\n",
       " 'ft_campaign_gte10_3',\n",
       " 'remainder_False',\n",
       " 'remainder_True']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = [\n",
    "  # Don't incclude the last entry in the `named_transformers_` list since\n",
    "  # it's the `remainder` parameter for the ColumnTransformer\n",
    "  ['%s_%s' % (name, value) for value in values] for \n",
    "    name, values in list(zip(list(cat_ct.named_transformers_.keys())[1:], cat_pipeline.named_steps['ohe'].categories_))]\n",
    "\n",
    "cat_feature_names = [name for names in feature_names for name in names]\n",
    "cat_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyqIxDimz1aw"
   },
   "source": [
    "## Pipeline Creation, Classifier LightGBM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uBSPyrQgcWrB"
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8jmQziPa6_e"
   },
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vGkluaHCch2K"
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_union = FeatureUnion([\n",
    "    ('cat_pipeline', cat_pipeline),\n",
    "    ('age_campaign_ct', age_campaign_ct),\n",
    "    ('num_union', num_union),\n",
    "    ('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maarch/venv/lib/python3.8/site-packages/sklearn/preprocessing/_discretization.py:195: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33525, 82)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_union.fit(X_train)\n",
    "features = ft_union.transform(X_train)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jsfdg8TGaXsE"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# We have chosen the Light GBM Classifier. It's a relative new algorithm that is not only fast but has also a very good acuracy\n",
    "lgbm = LGBMClassifier(objective='binary', random_state=1909)\n",
    "smo = SMOTE(random_state=1909)\n",
    "scorer = make_scorer(f1_score, pos_label='Yes')\n",
    "\n",
    "# RandomizedSearchCV parameters\n",
    "params = {\n",
    "    'classifier__learning_rate': [0.05, 0.1, 0.5],    \n",
    "    'classifier__boosting' : ['gbdt'],\n",
    "    'classifier__max_depth' : [-1],\n",
    "    'classifier__feature_fraction' : [0.7,1.0],\n",
    "    'classifier__min_gain_to_split' : [0.0,0.01,0.05],\n",
    "    'classifier__min_data_in_leaf':[60, 65, 70],\n",
    "    'classifier__metric':['auc'],\n",
    "    'classifier__max_bin':[240, 245, 250],\n",
    "    'classifier__num_iterations':[245, 250, 255],\n",
    "    'classifier__num_leaves':[500, 505, 510],\n",
    "    'classifier__scale_pos_weight': [1, 100, 1000],\n",
    "    'sampling__sampling_strategy': [0.4, 0.8,'minority']\n",
    "    }\n",
    "\n",
    "rf = Pipeline(steps=[('ft_union', ft_union),\n",
    "                     ('sampling', smo),             ### SMOTE ###                     \n",
    "                     ('classifier', lgbm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "o4uNQb_LaIcW",
    "outputId": "4db22251-55bb-4de5-c6e1-50cae1446de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.3min\n",
      "/home/maarch/venv/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:703: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 16.3min finished\n",
      "/home/maarch/venv/lib/python3.8/site-packages/sklearn/preprocessing/_discretization.py:195: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 0 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "/home/maarch/venv/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ft_union',\n",
       "                                              FeatureUnion(n_jobs=None,\n",
       "                                                           transformer_list=[('cat_pipeline',\n",
       "                                                                              Pipeline(memory=None,\n",
       "                                                                                       steps=[('cat_ct',\n",
       "                                                                                               ColumnTransformer(n_jobs=None,\n",
       "                                                                                                                 remainder='drop',\n",
       "                                                                                                                 sparse_threshold=0.3,\n",
       "                                                                                                                 transformer_weights=None,\n",
       "                                                                                                                 transformers=[('ft_pcontacted_last_campaign',\n",
       "                                                                                                                                FunctionTransformer(acce...\n",
       "                                        'classifier__min_gain_to_split': [0.0,\n",
       "                                                                          0.01,\n",
       "                                                                          0.05],\n",
       "                                        'classifier__num_iterations': [245, 250,\n",
       "                                                                       255],\n",
       "                                        'classifier__num_leaves': [500, 505,\n",
       "                                                                   510],\n",
       "                                        'classifier__scale_pos_weight': [1, 100,\n",
       "                                                                         1000],\n",
       "                                        'sampling__sampling_strategy': [0.4,\n",
       "                                                                        0.8,\n",
       "                                                                        'minority']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True,\n",
       "                   scoring=make_scorer(f1_score, pos_label=Yes), verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch\n",
    "#grid = GridSearchCV(rf, params, scoring=scorer, verbose=1, cv=5, n_jobs=-1, return_train_score=True)\n",
    "#grid.fit(X_train, y_train)\n",
    "\n",
    "# RandomizedSearch\n",
    "grid = RandomizedSearchCV(rf, params, scoring=scorer, verbose=1, cv=10, n_jobs=-1, n_iter=15, return_train_score=True)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bk2yEHSPbZgw"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HcQzgNyrzSe6"
   },
   "outputs": [],
   "source": [
    "training_score = grid.cv_results_['mean_train_score'][grid.best_index_] * 100\n",
    "test_score = grid.cv_results_['mean_test_score'][grid.best_index_] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUWUsiZQlWHr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99749103, 0.90749455,        nan,        nan,        nan,\n",
       "              nan, 0.8727955 , 0.84594336, 0.94890299, 0.99076894,\n",
       "       0.99982013, 0.74113656, 0.8770876 ,        nan, 0.92492088])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid.cv_results_['mean_fit_time']\n",
    "#grid.cv_results_['mean_score_time']\n",
    "grid.cv_results_['mean_train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGaAGRO7z04b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean F1 Score (Training/Test): 99.98%/90.63%'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Mean F1 Score (Training/Test): {training_score:.2f}%/{test_score:.2f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oukxLfKSl6PQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters = <bound method LGBMModel.get_params of LGBMClassifier(boosting='gbdt', boosting_type='gbdt', class_weight=None,\n",
      "               colsample_bytree=1.0, feature_fraction=1.0,\n",
      "               importance_type='split', learning_rate=0.5, max_bin=250,\n",
      "               max_depth=-1, metric='auc', min_child_samples=20,\n",
      "               min_child_weight=0.001, min_data_in_leaf=60,\n",
      "               min_gain_to_split=0.05, min_split_gain=0.0, n_estimators=100,\n",
      "               n_jobs=-1, num_iterations=250, num_leaves=510,\n",
      "               objective='binary', random_state=1909, reg_alpha=0.0,\n",
      "               reg_lambda=0.0, scale_pos_weight=1, silent=True, subsample=1.0,\n",
      "               subsample_for_bin=200000, subsample_freq=0)>\n"
     ]
    }
   ],
   "source": [
    "# importance of each attribute\n",
    "#print(grid.best_estimator_.named_steps[\"classifier\"].get_fscore())\n",
    "#grid.best_estimator_.named_steps[\"classifier\"].feature_importances_\n",
    "#fea_imp_.loc[fea_imp_.fea_imp > 0].sort_values(by=['fea_imp'], ascending = False)\n",
    "\n",
    "print(\"\\nBest Parameters = \" + str(grid.best_estimator_.named_steps['classifier'].get_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GBM on test set: 0.915\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.99      0.93      0.96      9868\n",
      "         Yes       0.86      0.98      0.92      4500\n",
      "\n",
      "    accuracy                           0.94     14368\n",
      "   macro avg       0.92      0.95      0.94     14368\n",
      "weighted avg       0.95      0.94      0.94     14368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictors=list(X_train)\n",
    "\n",
    "print('Accuracy of the GBM on test set: {:.3f}'.format(grid.score(X_test, y_test)))\n",
    "pred=grid.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataset = pd.read_csv('https://raw.githubusercontent.com/saschaschworm/big-data-and-data-science/master/datasets/prediction-challenge/prediction-dataset.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataset['days_since_last_contact'] = np.where(prediction_dataset['days_since_last_contact'].between(1,5), 1, prediction_dataset['days_since_last_contact'])\n",
    "prediction_dataset['days_since_last_contact'] = prediction_dataset['days_since_last_contact'].mask(prediction_dataset['days_since_last_contact'] >= 6, 2)\n",
    "prediction_dataset['days_since_last_contact'] = prediction_dataset['days_since_last_contact'].mask(prediction_dataset['days_since_last_contact'] == -1, 999)\n",
    "\n",
    "prediction_dataset['days_since_last_contact_cat'] = np.where(prediction_dataset['days_since_last_contact'].between(1,5), 1, prediction_dataset['days_since_last_contact'])\n",
    "prediction_dataset['days_since_last_contact_cat'] = prediction_dataset['days_since_last_contact'].mask(prediction_dataset['days_since_last_contact'] >= 6, 2)\n",
    "prediction_dataset['days_since_last_contact_cat'] = prediction_dataset['days_since_last_contact'].mask(prediction_dataset['days_since_last_contact'] == -1, 999)\n",
    "prediction_dataset['days_since_last_contact_cat'] = np.where(prediction_dataset['days_since_last_contact_cat'].between(1,5), 1, prediction_dataset['days_since_last_contact'])\n",
    "prediction_dataset['days_since_last_contact_cat'] = prediction_dataset['days_since_last_contact_cat'].mask(prediction_dataset['days_since_last_contact'] >= 6, 2)\n",
    "prediction_dataset['days_since_last_contact_cat'] = prediction_dataset['days_since_last_contact_cat'].mask(prediction_dataset['days_since_last_contact'] == -1, 999)\n",
    "\n",
    "prediction_dataset['n_contacts_before'] = np.where(prediction_dataset['n_contacts_before'].between(2,4), 1, prediction_dataset['n_contacts_before'])\n",
    "prediction_dataset['n_contacts_before'] = prediction_dataset['n_contacts_before'].mask(prediction_dataset['n_contacts_before'] == 0, 0)\n",
    "prediction_dataset['n_contacts_before'] = np.where(prediction_dataset['n_contacts_before'].between(5,6), 2, prediction_dataset['n_contacts_before'])\n",
    "prediction_dataset['n_contacts_before'] = prediction_dataset['n_contacts_before'].mask(prediction_dataset['n_contacts_before'] == 7, 3)\n",
    "\n",
    "prediction_dataset['previous_conversion_bin'] = prediction_dataset['previous_conversion'].mask(prediction_dataset['previous_conversion'] == \"Inexistent\", 0)\n",
    "prediction_dataset['previous_conversion_bin'] = prediction_dataset['previous_conversion'].mask(prediction_dataset['previous_conversion'] == \"Failed\", 2)\n",
    "prediction_dataset['previous_conversion_bin'] = prediction_dataset['previous_conversion'].mask(prediction_dataset['previous_conversion'] == \"Successful\", 1)\n",
    "prediction_dataset['previous_conversion_bin'] = prediction_dataset['previous_conversion_bin'].mask(prediction_dataset['previous_conversion'] == \"Inexistent\", 0)\n",
    "prediction_dataset['previous_conversion_bin'] = prediction_dataset['previous_conversion_bin'].mask(prediction_dataset['previous_conversion'] == \"Failed\", 2)\n",
    "prediction_dataset['previous_conversion_bin'] = prediction_dataset['previous_conversion_bin'].mask(prediction_dataset['previous_conversion'] == \"Successful\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataset[\"days_since_last_contact_cat\"] = prediction_dataset[\"days_since_last_contact_cat\"].astype('object')\n",
    "prediction_dataset[\"n_contacts_before\"] = prediction_dataset[\"n_contacts_before\"].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 109 features\n",
      "Elapsed: 00:00 | Progress: 100%|██████████\n"
     ]
    }
   ],
   "source": [
    "es = ft.EntitySet(id = 'pred')\n",
    "\n",
    "variable_types = {\"identifier\": vtypes.Index, \"age\":vtypes.Ordinal ,\"marital_status\": vtypes.Categorical, \n",
    "                                                \"education\": vtypes.Categorical, \"job\": vtypes.Categorical, \"credit_default\": vtypes.Boolean, \n",
    "                                                \"housing_loan\": vtypes.Boolean, \"personal_loan\": vtypes.Boolean, \"communication_type\": vtypes.Categorical,\n",
    "                                                \"n_contacts_before\": vtypes.variable.Ordinal, \"previous_conversion\": vtypes.Categorical, \n",
    "                                                \"duration\": vtypes.Datetime, \"previous_conversion_bin\": vtypes.Categorical,\n",
    "                                                \"days_since_last_contact_cat\": vtypes.Categorical}\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id='pred', \n",
    "                              dataframe = prediction_dataset, \n",
    "                              index = 'identifier', \n",
    "                              time_index = 'date')\n",
    "\n",
    "es = es.normalize_entity(base_entity_id='pred', new_entity_id='days_since_last_contact', index='days_since_last_contact')\n",
    "es = es.normalize_entity(base_entity_id='pred', new_entity_id='previous_conversion', index='previous_conversion')\n",
    "\n",
    "prediction_dataset, prediction_dataset_names = ft.dfs(entityset=es,\n",
    "    target_entity = 'pred',\n",
    "    max_depth = 2,\n",
    "    verbose = 3,\n",
    "    n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dataset = prediction_dataset.loc[:,prediction_dataset.apply(pd.Series.nunique) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new =pd.DataFrame(prediction_dataset, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.best_estimator_.predict(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(predictions, index=df_new.index, columns=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrikel_mheichler = '465475'\n",
    "matrikel_psaustum = '470057'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f'./submission-{matrikel_mheichler}-{matrikel_psaustum}.csv', index_label='identifier')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KA5XN4WBx0ye",
    "bVfAOpJytysp",
    "SlAgDebQTC1V"
   ],
   "name": "Umsetzung_50upsampling50smote_lgbm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venvPy3",
   "language": "python",
   "name": "venvpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
